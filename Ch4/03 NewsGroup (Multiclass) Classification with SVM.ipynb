{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NewGroup Classification with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiClass classification\n",
    "MultiClass classification are one the most tediuos learning for any Classification Method.\n",
    "\n",
    "There are few major ways these problems are learnt:\n",
    "1. One vs Rest   : Treating each \"Class\" as binary classificaiton problem with rest as \"Other Class\"\n",
    "2. One vs One    : Treating combination of \"Two Class\" at a time as binary classification problem\n",
    "3. Carrmer Singer: Joint optimisation over all classes at same time.\n",
    "\n",
    "The models which support MultiClass Classificaiton are (not exhaustive):\n",
    "1. Support Vector Machines (SVM)\n",
    "2. Naive Bayes (NB)\n",
    "3. K-Nearest Neighbours (KNN)\n",
    "4. Decision Trees (All variants)\n",
    "5. Neural Networks (ANN and DNN)\n",
    "6. Quadratic Discriminant Analysis (QDA) and LDA\n",
    "7. Learning Vector Quantization (LVQ)\n",
    "\n",
    "More Details:\n",
    "* [Wikipedia](https://en.wikipedia.org/wiki/Multiclass_classification)\n",
    "* [Survey on Multiclass Classification Method](https://www.cs.utah.edu/~piyush/teaching/aly05multiclass.pdf)\n",
    "* [Crammer and Singer](http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf)\n",
    "\n",
    "\n",
    "## News Group Data\n",
    "This data is all about news feed for 20 groups of data. More details [NewGroup](http://qwone.com/~jason/20Newsgroups/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# For Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# For ML models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# For Model Selection based on GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# other imports\n",
    "import numpy as np\n",
    "\n",
    "# for stopwords and data cleaning\n",
    "import nltk\n",
    "# nltk.download() # use this if you haven't ownloaded any stemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# for Pipeline flow of processing with sklearn\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The News Group data can directly fectched using scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Names:\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n",
      "Sample data:\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Getting Class distributions:\n",
      "[['alt.atheism' '480']\n",
      " ['comp.graphics' '584']\n",
      " ['comp.os.ms-windows.misc' '591']\n",
      " ['comp.sys.ibm.pc.hardware' '590']\n",
      " ['comp.sys.mac.hardware' '578']\n",
      " ['comp.windows.x' '593']\n",
      " ['misc.forsale' '585']\n",
      " ['rec.autos' '594']\n",
      " ['rec.motorcycles' '598']\n",
      " ['rec.sport.baseball' '597']\n",
      " ['rec.sport.hockey' '600']\n",
      " ['sci.crypt' '595']\n",
      " ['sci.electronics' '591']\n",
      " ['sci.med' '594']\n",
      " ['sci.space' '593']\n",
      " ['soc.religion.christian' '599']\n",
      " ['talk.politics.guns' '546']\n",
      " ['talk.politics.mideast' '564']\n",
      " ['talk.politics.misc' '465']\n",
      " ['talk.religion.misc' '377']]\n"
     ]
    }
   ],
   "source": [
    "# For fetching the dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "#Loading the data set \n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "#print labels (categories).\n",
    "print('Target Names:\\n{}\\n'.format(twenty_train.target_names))\n",
    "\n",
    "# print some data\n",
    "print('Sample data:')\n",
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\"))) \n",
    "\n",
    "# Print distribution of classes\n",
    "unique, counts = np.unique(twenty_train.target, return_counts=True)\n",
    "print('Getting Class distributions:')\n",
    "print(np.asarray((twenty_train.target_names, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The data is in form of mail from people.\n",
    "Now lets try to extract some information from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting features from text files - tf-idf\n",
    "\n",
    "# Fitting on training data\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "# Processing on test data\n",
    "X_test_tfidf = tfidf_transformer.transform(count_vect.transform(twenty_test.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### As we can observe its a very wide sparse matrix. We'll use this matrix as over features to train our models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 120 ms, total: 13.7 s\n",
      "Wall time: 6.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Lets make very basic Linear SVM Classifier\n",
    "clf_svm = LinearSVC(dual=False, tol=0.0001, C=1.0, multi_class='ovr',verbose=0, random_state=None, max_iter=1000)\n",
    "\n",
    "# Fitting data on Classifier\n",
    "clf_svm = clf_svm.fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "# Making Prediciton\n",
    "predicted = clf_svm.predict(X_test_tfidf)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Without Any preprocessing we can see a very good accuracy. \n",
    "Another way to look at behaviour of model accross class in sklearn is via 'classification_report'.\n",
    "\n",
    "Lets see how the report looks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.82      0.81       309\n",
      "          1       0.80      0.76      0.78       412\n",
      "          2       0.73      0.77      0.75       376\n",
      "          3       0.76      0.71      0.74       416\n",
      "          4       0.86      0.84      0.85       392\n",
      "          5       0.76      0.87      0.81       347\n",
      "          6       0.91      0.83      0.87       424\n",
      "          7       0.91      0.92      0.91       390\n",
      "          8       0.95      0.95      0.95       399\n",
      "          9       0.95      0.92      0.93       412\n",
      "         10       0.98      0.96      0.97       408\n",
      "         11       0.94      0.93      0.93       400\n",
      "         12       0.79      0.81      0.80       384\n",
      "         13       0.87      0.90      0.88       380\n",
      "         14       0.93      0.90      0.92       407\n",
      "         15       0.93      0.84      0.88       445\n",
      "         16       0.92      0.75      0.82       447\n",
      "         17       0.89      0.97      0.93       345\n",
      "         18       0.62      0.82      0.71       234\n",
      "         19       0.61      0.75      0.68       205\n",
      "\n",
      "avg / total       0.86      0.85      0.85      7532\n",
      "\n",
      "CPU times: user 12.4 ms, sys: 60 Âµs, total: 12.5 ms\n",
      "Wall time: 6.81 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# importing classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(predicted,twenty_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see few classes have very low precision. As a rule of thumb: \n",
    "### \"Accuracy is not a sufficient statistic for MultiClass Classificaiton Problem. We should look depeer.\" \n",
    "\n",
    "As in case of above we can observe why so.\n",
    "\n",
    "Now lets try to imporve this a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.915762, total=  16.7s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.917572, total=  17.8s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.917685, total=  17.8s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.898013, total=  18.9s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.902465, total=  14.9s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.900690, total=  15.4s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.920795, total= 1.0min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.921018, total= 1.1min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.921402, total= 1.2min\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.910464, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.913113, total=  38.1s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.917307, total=  38.8s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.912536, total= 1.2min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.909719, total= 1.2min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.916888, total=  27.8s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.896954, total=  29.1s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.904585, total=  30.2s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.901753, total=  25.6s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.920000, total= 3.4min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.922873, total= 3.5min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.921402, total= 3.6min\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.912848, total= 3.6min\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.912583, total=  20.6s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.916247, total=  23.4s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.918216, total=  23.0s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.896954, total=  24.4s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.900080, total=  21.9s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 1), score=0.898566, total=  28.5s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.912536, total= 2.6min\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=ovr, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.912108, total= 2.6min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n",
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.921060, total= 1.1min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.923403, total= 1.2min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.921402, total=  43.4s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.911741, total=  36.7s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.909669, total=  42.4s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.01, counter__ngram_range=(1, 2), score=0.909453, total=  34.9s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.916247, total=  59.4s\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.918216, total= 1.0min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1) \n",
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.896954, total=  42.6s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.900080, total=  30.4s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.898566, total=  41.1s\n",
      "[CV] tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 1), score=0.912583, total= 2.0min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.921060, total= 3.0min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.923403, total= 3.9min\n",
      "[CV] tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.909669, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=True, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.921402, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.911476, total= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  tfidf__use_idf=False, clf-svm__multi_class=crammer_singer, clf-svm__tol=0.0001, counter__ngram_range=(1, 2), score=0.909453, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 18.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitins_lab/anaconda2/envs/nlpstack/lib/python3.4/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lets create a pipeline to mke things bit easy for iterations.\n",
    "# Also we'll remove stopwords from the text to reduce our corpus size as well as reduce the noise in data. \n",
    "news_clf_svm = Pipeline([('counter', CountVectorizer(stop_words='english')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', LinearSVC(dual=False, # As the feature space is much bigger than data\n",
    "                                            class_weight='balanced', # As we have different class distribution\n",
    "                                            C=10, # making the class bit more seperable\n",
    "                                            verbose=1, random_state=234, max_iter=1000)) \n",
    "                         ])\n",
    "\n",
    "# Now lets make a grid search to see what best works on this data set.\n",
    "grid_param = {'counter__ngram_range': [(1, 1), (1, 2)],\n",
    "                'tfidf__use_idf': (True, False),\n",
    "                'clf-svm__multi_class': ('ovr','crammer_singer'),\n",
    "                'clf-svm__tol':(1e-2, 1e-4)\n",
    "             }\n",
    "                   \n",
    "# Fitting the Data on the models generated by grid search\n",
    "news_gs_clf = GridSearchCV(news_clf_svm, grid_param, n_jobs=-1,verbose=5)\n",
    "news_gs_clf = news_gs_clf.fit(twenty_train.data, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921955099876\n",
      "{'tfidf__use_idf': True, 'clf-svm__multi_class': 'crammer_singer', 'clf-svm__tol': 0.01, 'counter__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# Print the statistics                        \n",
    "print(news_gs_clf.best_score_)\n",
    "print(news_gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8601964949548593\n",
      " Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.85      0.82       298\n",
      "          1       0.82      0.76      0.79       419\n",
      "          2       0.75      0.78      0.77       377\n",
      "          3       0.77      0.72      0.74       417\n",
      "          4       0.87      0.82      0.84       410\n",
      "          5       0.77      0.87      0.81       350\n",
      "          6       0.90      0.82      0.86       429\n",
      "          7       0.90      0.93      0.91       383\n",
      "          8       0.96      0.95      0.96       399\n",
      "          9       0.95      0.91      0.93       411\n",
      "         10       0.98      0.97      0.97       405\n",
      "         11       0.95      0.93      0.94       404\n",
      "         12       0.79      0.82      0.80       375\n",
      "         13       0.86      0.90      0.88       378\n",
      "         14       0.92      0.90      0.91       406\n",
      "         15       0.94      0.88      0.91       425\n",
      "         16       0.92      0.78      0.84       433\n",
      "         17       0.90      0.97      0.94       349\n",
      "         18       0.66      0.86      0.75       237\n",
      "         19       0.69      0.76      0.72       227\n",
      "\n",
      "avg / total       0.86      0.86      0.86      7532\n",
      "\n",
      "CPU times: user 4.06 s, sys: 15.7 ms, total: 4.08 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Making Prediciton\n",
    "predicted = news_gs_clf.predict(twenty_test.data)\n",
    "print('Accuracy: {}\\n Classification Report:'.format(np.mean(predicted == twenty_test.target)))\n",
    "\n",
    "# generating classification report\n",
    "print(classification_report(predicted,twenty_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### As we can see class based predition has improved from the previous report.\n",
    "\n",
    "Note: We have used whole text as one corpus. If we use same setting and do some preprocessing then we can stil get even better results. That's upto you how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also lets use Stemming, from nltk package, to data and see if it improves\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "# Making CountVectorizer class\n",
    "class StemmedVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "stemmed_counter = StemmedVectorizer(ngram_range=(1,2), # from grid cv \n",
    "                                    stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy: 0.8586032926181625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.85      0.83       299\n",
      "          1       0.80      0.78      0.79       403\n",
      "          2       0.74      0.78      0.76       370\n",
      "          3       0.75      0.71      0.73       413\n",
      "          4       0.86      0.81      0.84       409\n",
      "          5       0.78      0.87      0.82       356\n",
      "          6       0.88      0.80      0.84       431\n",
      "          7       0.91      0.93      0.92       389\n",
      "          8       0.96      0.96      0.96       398\n",
      "          9       0.94      0.92      0.93       404\n",
      "         10       0.98      0.96      0.97       409\n",
      "         11       0.96      0.92      0.94       413\n",
      "         12       0.80      0.82      0.81       385\n",
      "         13       0.86      0.89      0.88       384\n",
      "         14       0.93      0.90      0.92       407\n",
      "         15       0.93      0.88      0.91       421\n",
      "         16       0.93      0.78      0.84       434\n",
      "         17       0.91      0.98      0.95       351\n",
      "         18       0.65      0.85      0.74       234\n",
      "         19       0.67      0.76      0.71       222\n",
      "\n",
      "avg / total       0.86      0.86      0.86      7532\n",
      "\n",
      "CPU times: user 6min 25s, sys: 2.2 s, total: 6min 27s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Now lest create pipline with parameters from grid search\n",
    "news_clf = Pipeline([('counter', stemmed_counter),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', LinearSVC(dual=False, # As the feature space is much bigger than data\n",
    "                                            class_weight='balanced', # As we have different class distribution\n",
    "                                            C=100, # making the class bit more seperable\n",
    "                                            verbose=5, random_state=505, max_iter=1000)) \n",
    "                         ])\n",
    "\n",
    "# fitting on extracted training data\n",
    "news_clf= news_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "# Making Prediciton on extrated testing data\n",
    "predicted = news_clf.predict(twenty_test.data)\n",
    "print('Accuracy: {}'.format(np.mean(predicted == twenty_test.target)))\n",
    "\n",
    "# generating classification report\n",
    "print(classification_report(predicted,twenty_test.target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Though stemming takes longer time the effect on overall behaviour of data is less. This significantly indicates that data need lot of cleaning and processing before modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Part: Lets use Naive Bayes Classifier for the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7914232607541157\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.75      0.74       309\n",
      "          1       0.69      0.76      0.72       352\n",
      "          2       0.76      0.73      0.74       408\n",
      "          3       0.73      0.65      0.69       442\n",
      "          4       0.75      0.82      0.78       354\n",
      "          5       0.74      0.84      0.79       348\n",
      "          6       0.77      0.85      0.81       354\n",
      "          7       0.86      0.88      0.87       385\n",
      "          8       0.94      0.90      0.92       415\n",
      "          9       0.88      0.85      0.86       411\n",
      "         10       0.97      0.78      0.87       496\n",
      "         11       0.96      0.74      0.84       512\n",
      "         12       0.53      0.84      0.65       249\n",
      "         13       0.71      0.90      0.80       313\n",
      "         14       0.93      0.78      0.85       471\n",
      "         15       0.95      0.70      0.80       542\n",
      "         16       0.93      0.66      0.77       511\n",
      "         17       0.92      0.91      0.92       381\n",
      "         18       0.54      0.87      0.67       193\n",
      "         19       0.30      0.87      0.45        86\n",
      "\n",
      "avg / total       0.83      0.79      0.80      7532\n",
      "\n",
      "CPU times: user 20.9 s, sys: 632 ms, total: 21.6 s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A pipeline with MultinomialNB\n",
    "news_clf_nb = Pipeline([('counter', CountVectorizer(ngram_range=(1,2),stop_words='english')),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', MultinomialNB(alpha=10.0, fit_prior=False))\n",
    "                       ])\n",
    "\n",
    "# fitting on NB pipeline\n",
    "news_clf_nb= news_clf_nb.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "# Making Prediciton on extrated testing data\n",
    "predicted = news_clf_nb.predict(twenty_test.data)\n",
    "print('Accuracy: {}'.format(np.mean(predicted == twenty_test.target)))\n",
    "\n",
    "# generating classification report\n",
    "print(classification_report(predicted,twenty_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The next steps ideally inclueds the data preprocesing, feature generation and more hyperparameter tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlpstack]",
   "language": "python",
   "name": "conda-env-nlpstack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
